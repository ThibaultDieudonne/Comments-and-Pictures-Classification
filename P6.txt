Todo:

Chunks

transfer learning avec fine-tuning partiel en utilisant un CNN (de Keras ?) et les données labelisées de Yelp (need GPU tensorflow)

Enrichissement de la bdd avec l'API

Visualisation des données avec réduction de dimension

----------------------------------------

Questions:

Hyperparameters ? (batch_size, epochs)

Conversion en tensor pas scalable ?

Ca semble pas très opti de devoir charger et tokeniser pour trouver les mots les plus fréquents, pour ensuite recharger et les supprimer + process 

Learning avec GPU ? Numba ?

Bénéfice pipelines ?

"le bruit sur les images a été filtré" ?

"l’histogramme a été égalisée sur les images" ?

Quand utiliser embedding ?
  [https://www.kaggle.com/vukglisovic/classification-combining-lda-and-word2vec
  model1 = gensim.models.Word2Vec(tokenized_text, min_count = 1, vector_size = 100, window = 5)]

----------------------------------------

Divers:

  Mise à jour via GraphQL ou API normale (existe-t-il un moyen de récuperer les modifications après une date spécifique) ?

  Doc learning rate / decay ? => default_rate = 0.001, custom decay

-----------------------------------------

Balance target ? => pourquoi pas, sans bruit

-----------------------------------------

Architecture transformers (modèle d'attention, permet de prendre en compte les négations par exemple)

Notes:

tar xvf yelp_dataset.tar
tar xvf yelp_photos.tar

une justification du fait d’appliquer une réduction de dimension sur les données textes et images a été donnée => pour l'affichage

Doc:

image preprocessing: https://towardsdatascience.com/image-pre-processing-c1aec0be3edf

word2vec: https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html#sphx-glr-auto-examples-tutorials-run-word2vec-py

precomputed embedding: https://fasttext.cc/docs/en/english-vectors.html

sentiment/topic classification: https://aclanthology.org/P12-2018/

https://colah.github.io/posts/2015-08-Understanding-LSTMs/

https://fr.wikipedia.org/wiki/Scale-invariant_feature_transform

https://simoninithomas.github.io/deep-rl-course/
