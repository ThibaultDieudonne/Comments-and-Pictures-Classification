{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "527d7230",
   "metadata": {},
   "source": [
    "# Am√©liorez le produit IA de votre start-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9d71684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### basic libs\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "import warnings\n",
    "# api\n",
    "from gql import gql, Client\n",
    "from gql.transport.requests import RequestsHTTPTransport\n",
    "# text \n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# image\n",
    "import tensorflow as tf\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.width', None)\n",
    "# pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "\n",
    "\n",
    "debug = 1\n",
    "\n",
    "if debug:\n",
    "    nrows = 1000\n",
    "else:\n",
    "    nrows = None\n",
    "    \n",
    "filename = './yelp_dataset/yelp_academic_dataset_review.json'\n",
    "\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d31d4f4",
   "metadata": {},
   "source": [
    "### API queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5c7c23ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"api.key\", \"r\") as f:\n",
    "    api_key = f.readline()\n",
    "\n",
    "\n",
    "header = {'Authorization': f'bearer {api_key}',\n",
    "         'Content-Type': 'application/json'}\n",
    "\n",
    "# Select your transport with a defined url endpoint\n",
    "transport = RequestsHTTPTransport(url=\"https://api.yelp.com/v3/graphql\", headers=header, use_json=True)\n",
    "\n",
    "# Create a GraphQL client using the defined transport\n",
    "client = Client(transport=transport, fetch_schema_from_transport=True)\n",
    "\n",
    "# Provide a GraphQL query\n",
    "query = gql(\n",
    "    \"\"\"\n",
    "    {\n",
    "      search(term:\"restaurants\",\n",
    "             location:\"san francisco\") {\n",
    "        business {\n",
    "          reviews {\n",
    "            text\n",
    "            rating\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Execute the query on the transport\n",
    "result = client.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b5cf8e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our whole family enjoyed Farmhouse Kitchen!\\n\\...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Value is playing a role in my review, I don't ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I think this place is overhyped. I've been rea...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Food aside, I would go here again for the ador...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I recently found this place while searching fo...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text rating\n",
       "0  Our whole family enjoyed Farmhouse Kitchen!\\n\\...      5\n",
       "1  Value is playing a role in my review, I don't ...      3\n",
       "2  I think this place is overhyped. I've been rea...      2\n",
       "3  Food aside, I would go here again for the ador...      5\n",
       "4  I recently found this place while searching fo...      5"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews = pd.DataFrame(columns=['text', 'rating'])\n",
    "\n",
    "for business in result[\"search\"][\"business\"]:\n",
    "    for review in business[\"reviews\"]:\n",
    "        df_reviews = df_reviews.append(review, ignore_index=True)\n",
    "\n",
    "df_reviews.to_csv('new_reviews.csv')\n",
    "\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e19882c",
   "metadata": {},
   "source": [
    "### Comments analysis Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c42b4889",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = EnglishStemmer()\n",
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "stop_words = [stemmer.stem(w) for w in list(nltk.corpus.stopwords.words('english'))]\n",
    "\n",
    "def clean_up(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [stemmer.stem(w) for w in tokens]\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4afd7ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_negative_comments(comments):\n",
    "    negative_comments = comments[comments[\"stars\"]<3][\"text\"].to_list()\n",
    "\n",
    "    for comment_id in range(len(negative_comments)):\n",
    "        negative_comments[comment_id] = negative_comments[comment_id].replace('\\n', ' ')\n",
    "        \n",
    "    return negative_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6ad8cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_json(filename, lines=True, nrows=nrows)\n",
    "\n",
    "negative_comments = get_negative_comments(comments)\n",
    "\n",
    "tokenized_text = [*map(clean_up, negative_comments)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1baaac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = {}\n",
    "for comment in tokenized_text:\n",
    "    for word in list(set(comment)):\n",
    "        if word in freqs:\n",
    "            freqs[word] += 1\n",
    "        else:\n",
    "            freqs[word] = 1\n",
    "\n",
    "freqs_list = [(x, freqs[x]/nrows)for x in freqs]\n",
    "freqs_list = sorted(freqs_list, key=lambda x:x[1])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "466e6e03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(freqs_list[:500])\n",
    "\n",
    "n = 200 # deleting the 200 most used words\n",
    "\n",
    "n_frequent = [freqs_list[x][0]for x in range(n)]\n",
    "\n",
    "def clear_words(tokens):\n",
    "    return [w for w in tokens if not w in n_frequent]\n",
    "\n",
    "tokenized_text = [*map(clear_words, tokenized_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bd7bc0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [' '.join(comment) for comment in tokenized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8648707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 10\n",
    "\n",
    "vectoriser = CountVectorizer(max_df=.6, min_df=10, max_features=100)\n",
    "vectorized = vectoriser.fit_transform(text)\n",
    "\n",
    "lda = LatentDirichletAllocation(\n",
    "        n_components=n_topics, \n",
    "        max_iter=5, \n",
    "        learning_method='online', \n",
    "        learning_offset=50.,\n",
    "        random_state=42).fit(vectorized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "23092ee1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "hard fix drive yelp pick wrong sorri owner problem treat\n",
      "Topic 1:\n",
      "sandwich sauc bread appet plate dinner item chang bring arriv\n",
      "Topic 2:\n",
      "okay kid waiter almost bread past drive quick half sat\n",
      "Topic 3:\n",
      "poor door night total absolut understand probabl 20 decent may\n",
      "Topic 4:\n",
      "free cook enough clean kid home park wast select bread\n",
      "Topic 5:\n",
      "phone let decent later item clear store issu sat problem\n",
      "Topic 6:\n",
      "shop item wish move horribl store bring mean wrong month\n",
      "Topic 7:\n",
      "card clean credit wast care ago sat dinner send store\n",
      "Topic 8:\n",
      "care across overal point matter recent may yelp soon arriv\n",
      "Topic 9:\n",
      "employe dri notic item gave clear respons woman home matter\n"
     ]
    }
   ],
   "source": [
    "def display_topics(model, feature_names, ntw): # do multiple runs and hyperparameters optimization\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic {}:\".format(topic_idx))\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-ntw-1:-1]]))\n",
    "\n",
    "n_top_words = 10\n",
    "display_topics(lda, vectoriser.get_feature_names(), n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0276376b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_names = vectoriser.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9fc5fe03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>20</th>\n",
       "      <th>absolut</th>\n",
       "      <th>across</th>\n",
       "      <th>ago</th>\n",
       "      <th>almost</th>\n",
       "      <th>appet</th>\n",
       "      <th>arriv</th>\n",
       "      <th>base</th>\n",
       "      <th>bit</th>\n",
       "      <th>bland</th>\n",
       "      <th>...</th>\n",
       "      <th>treat</th>\n",
       "      <th>understand</th>\n",
       "      <th>waiter</th>\n",
       "      <th>wast</th>\n",
       "      <th>wish</th>\n",
       "      <th>without</th>\n",
       "      <th>woman</th>\n",
       "      <th>write</th>\n",
       "      <th>wrong</th>\n",
       "      <th>yelp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      20  absolut  across    ago  almost  appet  arriv   base    bit  bland  \\\n",
       "0  False    False   False  False   False  False  False  False  False  False   \n",
       "1  False    False   False  False   False  False  False  False  False  False   \n",
       "2  False    False   False  False   False  False  False  False  False  False   \n",
       "3  False    False   False  False   False  False  False  False  False  False   \n",
       "4  False    False   False  False   False  False  False  False  False  False   \n",
       "\n",
       "   ...  treat  understand  waiter   wast   wish  without  woman  write  wrong  \\\n",
       "0  ...  False       False   False  False  False    False  False  False  False   \n",
       "1  ...  False       False   False  False  False    False  False  False  False   \n",
       "2  ...  False       False   False  False  False    False  False  False  False   \n",
       "3  ...  False       False   False  False  False    False  False  False  False   \n",
       "4  ...  False       False   False  False  False     True   True  False  False   \n",
       "\n",
       "    yelp  \n",
       "0  False  \n",
       "1  False  \n",
       "2  False  \n",
       "3  False  \n",
       "4  False  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df = pd.DataFrame(columns=features_names, data=vectorized.toarray())\n",
    "for col_name in features_names:\n",
    "    words_df[col_name] = words_df[col_name].astype('bool')\n",
    "words_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f2b68e",
   "metadata": {},
   "source": [
    "### Picture analysis baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1705d288",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = None\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d45d5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(name):\n",
    "    return os.path.join(\"preprocessed_imgs\", f\"{name}.jpg\")\n",
    "\n",
    "def load_img(path, tgt):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.io.decode_jpeg(img)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.keras.applications.vgg16.preprocess_input(img)\n",
    "    tgt = tf.reshape(tgt, [1])\n",
    "    return img, tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4c65475a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113204</th>\n",
       "      <td>preprocessed_imgs\\pktBAPWe9XbDGIfyejuj-A.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47646</th>\n",
       "      <td>preprocessed_imgs\\M9-HDkj4o_vCOJFp_6F_3Q.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94950</th>\n",
       "      <td>preprocessed_imgs\\eaQS-wZl6TQGWYrdc4K0JQ.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73564</th>\n",
       "      <td>preprocessed_imgs\\6-zZR29_OcHg0-8_6e7BLg.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74545</th>\n",
       "      <td>preprocessed_imgs\\ycH4ILdISi1XM2z_GTpWFA.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  label\n",
       "113204  preprocessed_imgs\\pktBAPWe9XbDGIfyejuj-A.jpg      0\n",
       "47646   preprocessed_imgs\\M9-HDkj4o_vCOJFp_6F_3Q.jpg      3\n",
       "94950   preprocessed_imgs\\eaQS-wZl6TQGWYrdc4K0JQ.jpg      0\n",
       "73564   preprocessed_imgs\\6-zZR29_OcHg0-8_6e7BLg.jpg      3\n",
       "74545   preprocessed_imgs\\ycH4ILdISi1XM2z_GTpWFA.jpg      3"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pictures = pd.read_json(\"photos.json\", lines=True, nrows=nrows)[[\"photo_id\", \"label\"]]\n",
    "pictures[\"path\"] = pictures[\"photo_id\"].apply(get_path)\n",
    "pictures = pictures[[\"path\", \"label\"]]\n",
    "pictures = pictures.sample(frac=1) # shuffle\n",
    "pictures[\"label\"] = pictures[\"label\"].apply(lambda x:  {'interior': 0, 'outside': 1, 'menu': 2, 'food': 3, 'drink': 4}[x])\n",
    "\n",
    "pictures = pictures.head(100) # warning\n",
    "\n",
    "pictures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5e8b2493",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "ds = tf.data.Dataset.from_tensor_slices((pictures[\"path\"].values, tf.cast(pictures[\"label\"].values, tf.int32))).shuffle(BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ecb182c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map(load_img, num_parallel_calls=AUTOTUNE)\n",
    "ds = ds.repeat()\n",
    "ds = ds.batch(batch_size)\n",
    "ds = ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "734a799f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TakeDataset shapes: ((None, None, None, 3), (None, 1)), types: (tf.float32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.vgg16.VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "x = model.output\n",
    "predictions = tf.keras.layers.Flatten()(x)\n",
    "new_model = tf.keras.Model(inputs=model.input, outputs=predictions)\n",
    "\n",
    "\n",
    "img = ds.take(1)\n",
    "# pred = model.predict(img)\n",
    "print(img)\n",
    "# print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ba2f00f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b6f840b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 125445    \n",
      "=================================================================\n",
      "Total params: 14,840,133\n",
      "Trainable params: 14,727,557\n",
      "Non-trainable params: 112,576\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "256/256 - 51s - loss: nan - accuracy: 0.2095\n",
      "Epoch 2/10\n",
      "256/256 - 51s - loss: nan - accuracy: 0.2102\n",
      "Epoch 3/10\n",
      "256/256 - 51s - loss: nan - accuracy: 0.2095\n",
      "Epoch 4/10\n",
      "256/256 - 51s - loss: nan - accuracy: 0.2107\n",
      "Epoch 5/10\n",
      "256/256 - 51s - loss: nan - accuracy: 0.2102\n",
      "Epoch 6/10\n",
      "256/256 - 51s - loss: nan - accuracy: 0.2087\n",
      "Epoch 7/10\n",
      "256/256 - 51s - loss: nan - accuracy: 0.2104\n",
      "Epoch 8/10\n",
      "256/256 - 51s - loss: nan - accuracy: 0.2107\n",
      "Epoch 9/10\n",
      "256/256 - 51s - loss: nan - accuracy: 0.2092\n",
      "Epoch 10/10\n",
      "256/256 - 51s - loss: nan - accuracy: 0.2100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18b31469400>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_model():\n",
    "    model = tf.keras.applications.vgg16.VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "    x = model.output\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    predictions = tf.keras.layers.Dense(5, activation='softmax')(x)\n",
    "    new_model = tf.keras.Model(inputs=model.input, outputs=predictions)\n",
    "    for layer in model.layers[:5]:\n",
    "        layer.trainable = False\n",
    "    new_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "    print(new_model.summary())\n",
    "    model_info = new_model.fit(ds, batch_size=batch_size, epochs=10, steps_per_epoch=256, verbose=2)\n",
    "    \n",
    "    return model_info\n",
    "\n",
    "model = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c9d4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
